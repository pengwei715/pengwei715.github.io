---
layout: post
title: Diart
description: my learning note of the Diart paper
tags: audio, model
---
Note of the paper Diart

### Context

Speaker diarization is the task of solving "who speaks when"
This note is about the paper Diart. https://arxiv.org/abs/2109.06483

#### multi-stage vs end-to-end

1. multi-stage
    - voice activity detection to discard non-speech segments
    - speaker embedding extraction to get the speaker representation
    - clustering to group the speaker embeddings

2. end-to-end
    - BLSTM (bi-directional LSTM, two processing, one from past to future, one from future to past)
    - Self-attention mechanism

The challenge of multi-stage approach is the overlapping speech.
The challenge of end-to-end approach is unkown number of speakers and super hard to scale.


### Diart

This diart paper is a hybrid approach, which combines the advantages of both multi-stage and end-to-end. It's more towards the multi-stage approach with over-lapping speech as the first class citizen.

1. split the audio into small chuncks, in each chunck, do end-to-end.
2. apply global constrained clustering on top of the resulting local speaker.

![](/assets/img/2024-06-30-diart-img1.jpg)

